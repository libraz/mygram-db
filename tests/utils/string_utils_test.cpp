/**
 * @file string_utils_test.cpp
 * @brief Unit tests for string utility functions
 */

#include "utils/string_utils.h"

#include <gtest/gtest.h>

using namespace mygramdb::utils;

/**
 * @brief Test UTF-8 to codepoints conversion
 */
TEST(StringUtilsTest, Utf8ToCodepoints) {
  // ASCII
  auto codepoints = Utf8ToCodepoints("abc");
  ASSERT_EQ(codepoints.size(), 3);
  EXPECT_EQ(codepoints[0], 0x61);  // 'a'
  EXPECT_EQ(codepoints[1], 0x62);  // 'b'
  EXPECT_EQ(codepoints[2], 0x63);  // 'c'

  // Japanese (Hiragana)
  codepoints = Utf8ToCodepoints("ã‚ã„");
  ASSERT_EQ(codepoints.size(), 2);
  EXPECT_EQ(codepoints[0], 0x3042);  // 'ã‚'
  EXPECT_EQ(codepoints[1], 0x3044);  // 'ã„'

  // Mixed
  codepoints = Utf8ToCodepoints("aã‚b");
  ASSERT_EQ(codepoints.size(), 3);
  EXPECT_EQ(codepoints[0], 0x61);    // 'a'
  EXPECT_EQ(codepoints[1], 0x3042);  // 'ã‚'
  EXPECT_EQ(codepoints[2], 0x62);    // 'b'

  // Empty
  codepoints = Utf8ToCodepoints("");
  EXPECT_EQ(codepoints.size(), 0);
}

/**
 * @brief Test codepoints to UTF-8 conversion
 */
TEST(StringUtilsTest, CodepointsToUtf8) {
  // ASCII
  std::string text = CodepointsToUtf8({0x61, 0x62, 0x63});
  EXPECT_EQ(text, "abc");

  // Japanese
  text = CodepointsToUtf8({0x3042, 0x3044});
  EXPECT_EQ(text, "ã‚ã„");

  // Mixed
  text = CodepointsToUtf8({0x61, 0x3042, 0x62});
  EXPECT_EQ(text, "aã‚b");

  // Empty
  text = CodepointsToUtf8({});
  EXPECT_EQ(text, "");
}

/**
 * @brief Test round-trip conversion
 */
TEST(StringUtilsTest, RoundTrip) {
  std::string original = "Helloä¸–ç•Œãƒ©ã‚¤ãƒ–";
  auto codepoints = Utf8ToCodepoints(original);
  std::string result = CodepointsToUtf8(codepoints);
  EXPECT_EQ(result, original);
}

/**
 * @brief Test unigram generation
 */
TEST(StringUtilsTest, GenerateUnigramsASCII) {
  auto ngrams = GenerateNgrams("abc", 1);
  ASSERT_EQ(ngrams.size(), 3);
  EXPECT_EQ(ngrams[0], "a");
  EXPECT_EQ(ngrams[1], "b");
  EXPECT_EQ(ngrams[2], "c");
}

/**
 * @brief Test unigram generation for Japanese text
 */
TEST(StringUtilsTest, GenerateUnigramsJapanese) {
  auto ngrams = GenerateNgrams("ãƒ©ã‚¤ãƒ–", 1);
  ASSERT_EQ(ngrams.size(), 3);
  EXPECT_EQ(ngrams[0], "ãƒ©");
  EXPECT_EQ(ngrams[1], "ã‚¤");
  EXPECT_EQ(ngrams[2], "ãƒ–");
}

/**
 * @brief Test bigram generation
 */
TEST(StringUtilsTest, GenerateBigrams) {
  auto ngrams = GenerateNgrams("abc", 2);
  ASSERT_EQ(ngrams.size(), 2);
  EXPECT_EQ(ngrams[0], "ab");
  EXPECT_EQ(ngrams[1], "bc");
}

/**
 * @brief Test bigram generation for Japanese
 */
TEST(StringUtilsTest, GenerateBigramsJapanese) {
  auto ngrams = GenerateNgrams("ãƒ©ã‚¤ãƒ–", 2);
  ASSERT_EQ(ngrams.size(), 2);
  EXPECT_EQ(ngrams[0], "ãƒ©ã‚¤");
  EXPECT_EQ(ngrams[1], "ã‚¤ãƒ–");
}

/**
 * @brief Test empty string
 */
TEST(StringUtilsTest, GenerateNgramsEmpty) {
  auto ngrams = GenerateNgrams("", 1);
  EXPECT_EQ(ngrams.size(), 0);
}

/**
 * @brief Test string shorter than n
 */
TEST(StringUtilsTest, GenerateNgramsTooShort) {
  auto ngrams = GenerateNgrams("a", 2);
  EXPECT_EQ(ngrams.size(), 0);
}

/**
 * @brief Test text normalization (basic lowercase)
 */
TEST(StringUtilsTest, NormalizeTextLowercase) {
  // ASCII lowercase
  std::string normalized = NormalizeText("ABC", false, "keep", true);
  EXPECT_EQ(normalized, "abc");

  // No lowercase
  normalized = NormalizeText("ABC", false, "keep", false);
  EXPECT_EQ(normalized, "ABC");
}

#ifdef USE_ICU
/**
 * @brief Test NFKC normalization with ICU
 *
 * NFKC (Normalization Form KC) is Compatibility Decomposition, followed by
 * Canonical Composition. It normalizes compatibility characters.
 */
TEST(StringUtilsTest, NormalizeTextNFKC) {
  // Full-width ASCII to half-width (compatibility normalization)
  // "ï¼¡ï¼¢ï¼£" (U+FF21, U+FF22, U+FF23) -> "ABC" (U+0041, U+0042, U+0043)
  std::string normalized = NormalizeText("ï¼¡ï¼¢ï¼£", true, "keep", false);
  EXPECT_EQ(normalized, "ABC");

  // Ligature decomposition: "ï¬" (U+FB01) -> "fi" (U+0066, U+0069)
  normalized = NormalizeText("ï¬le", true, "keep", false);
  EXPECT_EQ(normalized, "file");

  // Circled numbers: "â‘ â‘¡â‘¢" -> "123"
  normalized = NormalizeText("â‘ â‘¡â‘¢", true, "keep", false);
  EXPECT_EQ(normalized, "123");

  // Half-width katakana to full-width: "ï½±ï½²ï½³" -> "ã‚¢ã‚¤ã‚¦"
  normalized = NormalizeText("ï½±ï½²ï½³", true, "keep", false);
  EXPECT_EQ(normalized, "ã‚¢ã‚¤ã‚¦");
}

/**
 * @brief Test width conversion with ICU
 */
TEST(StringUtilsTest, NormalizeTextWidthConversion) {
  // Full-width to half-width (narrow)
  // "ï¼¡ï¼¢ï¼£" -> "ABC"
  std::string normalized = NormalizeText("ï¼¡ï¼¢ï¼£", false, "narrow", false);
  EXPECT_EQ(normalized, "ABC");

  // Full-width digits to half-width
  normalized = NormalizeText("ï¼‘ï¼’ï¼“", false, "narrow", false);
  EXPECT_EQ(normalized, "123");

  // Half-width to full-width (wide)
  // "ABC" -> "ï¼¡ï¼¢ï¼£"
  normalized = NormalizeText("ABC", false, "wide", false);
  EXPECT_EQ(normalized, "ï¼¡ï¼¢ï¼£");

  // Half-width digits to full-width
  normalized = NormalizeText("123", false, "wide", false);
  EXPECT_EQ(normalized, "ï¼‘ï¼’ï¼“");

  // Keep original width
  normalized = NormalizeText("ABC", false, "keep", false);
  EXPECT_EQ(normalized, "ABC");
}

/**
 * @brief Test combined normalization: NFKC + width + lowercase
 */
TEST(StringUtilsTest, NormalizeTextCombined) {
  // Full-width "ï¼¡ï¼¢ï¼£" -> NFKC -> narrow -> lowercase -> "abc"
  std::string normalized = NormalizeText("ï¼¡ï¼¢ï¼£", true, "narrow", true);
  EXPECT_EQ(normalized, "abc");

  // NFKC normalizes half-width katakana to full-width katakana
  // Full-width ASCII is converted to half-width by NFKC
  // "ï½±ï½²ï½³ï¼¡ï¼¢ï¼£" -> NFKC -> "ã‚¢ã‚¤ã‚¦ABC"
  // Note: Half-width katakana (ï½±ï½²ï½³) becomes full-width (ã‚¢ã‚¤ã‚¦) via NFKC
  // Full-width ASCII (ï¼¡ï¼¢ï¼£) becomes half-width (ABC) via NFKC
  normalized = NormalizeText("ï½±ï½²ï½³ï¼¡ï¼¢ï¼£", true, "keep", false);
  EXPECT_EQ(normalized, "ã‚¢ã‚¤ã‚¦ABC");

  // With lowercase
  normalized = NormalizeText("ï½±ï½²ï½³ï¼¡ï¼¢ï¼£", true, "keep", true);
  EXPECT_EQ(normalized, "ã‚¢ã‚¤ã‚¦abc");
}

/**
 * @brief Test Japanese text normalization for search
 *
 * This is a realistic test case for Japanese text search.
 */
TEST(StringUtilsTest, NormalizeTextJapaneseSearch) {
  // Normalize "ãƒ©ã‚¤ãƒ–" (full-width katakana) for search
  // NFKC keeps full-width katakana as-is
  std::string normalized = NormalizeText("ãƒ©ã‚¤ãƒ–", true, "keep", false);
  EXPECT_EQ(normalized, "ãƒ©ã‚¤ãƒ–");  // Full-width katakana stays as-is

  // Normalize "ï¾—ï½²ï¾Œï¾" (half-width katakana) for search
  // NFKC converts half-width katakana to full-width katakana
  normalized = NormalizeText("ï¾—ï½²ï¾Œï¾", true, "keep", false);
  EXPECT_EQ(normalized, "ãƒ©ã‚¤ãƒ–");  // Half-width -> full-width via NFKC

  // Both should normalize to the same form for matching
  std::string text1 = NormalizeText("ãƒ©ã‚¤ãƒ–", true, "keep", false);
  std::string text2 = NormalizeText("ï¾—ï½²ï¾Œï¾", true, "keep", false);
  EXPECT_EQ(text1, text2);
}

/**
 * @brief Test lowercase conversion for Japanese text
 */
TEST(StringUtilsTest, NormalizeTextJapaneseLowercase) {
  // Mixed ASCII + Japanese with lowercase
  // NFKC converts full-width ASCII to half-width
  std::string normalized = NormalizeText("ï¼¡ï¼¢ï¼£ã‚ã„ã†", true, "keep", true);
  EXPECT_EQ(normalized, "abcã‚ã„ã†");

  // Katakana should not be affected by lowercase
  normalized = NormalizeText("ãƒ©ã‚¤ãƒ–", true, "keep", true);
  EXPECT_EQ(normalized, "ãƒ©ã‚¤ãƒ–");
}

/**
 * @brief Test edge cases for normalization
 */
TEST(StringUtilsTest, NormalizeTextEdgeCases) {
  // Empty string
  std::string normalized = NormalizeText("", true, "narrow", true);
  EXPECT_EQ(normalized, "");

  // Single character
  normalized = NormalizeText("ï¼¡", true, "narrow", true);
  EXPECT_EQ(normalized, "a");

  // Spaces and punctuation
  normalized = NormalizeText("ã€€ï¼ï¼Ÿ", true, "narrow", false);
  EXPECT_EQ(normalized, " !?");  // Full-width space/punctuation to half-width
}
#endif  // USE_ICU

/**
 * @brief Test 4-byte UTF-8 characters (emojis)
 */
TEST(StringUtilsTest, FourByteEmoji) {
  // Single emoji (U+1F600 - ğŸ˜€)
  auto codepoints = Utf8ToCodepoints("ğŸ˜€");
  ASSERT_EQ(codepoints.size(), 1);
  EXPECT_EQ(codepoints[0], 0x1F600);

  // Round trip
  std::string emoji = CodepointsToUtf8({0x1F600});
  EXPECT_EQ(emoji, "ğŸ˜€");

  // Multiple emojis
  codepoints = Utf8ToCodepoints("ğŸ˜€ğŸ‰ğŸ‘");
  ASSERT_EQ(codepoints.size(), 3);
  EXPECT_EQ(codepoints[0], 0x1F600);  // ğŸ˜€
  EXPECT_EQ(codepoints[1], 0x1F389);  // ğŸ‰
  EXPECT_EQ(codepoints[2], 0x1F44D);  // ğŸ‘
}

/**
 * @brief Test emoji with text
 */
TEST(StringUtilsTest, EmojiWithText) {
  // Mixed: ASCII + Japanese + emoji
  auto codepoints = Utf8ToCodepoints("HelloğŸ˜€ä¸–ç•ŒğŸ‰");
  ASSERT_EQ(codepoints.size(), 9);    // H e l l o ğŸ˜€ ä¸– ç•Œ ğŸ‰
  EXPECT_EQ(codepoints[0], 0x48);     // 'H'
  EXPECT_EQ(codepoints[5], 0x1F600);  // ğŸ˜€
  EXPECT_EQ(codepoints[6], 0x4E16);   // ä¸–
  EXPECT_EQ(codepoints[7], 0x754C);   // ç•Œ
  EXPECT_EQ(codepoints[8], 0x1F389);  // ğŸ‰

  // Round trip
  std::string text = "HelloğŸ˜€ä¸–ç•ŒğŸ‰";
  auto cp = Utf8ToCodepoints(text);
  std::string result = CodepointsToUtf8(cp);
  EXPECT_EQ(result, text);
}

/**
 * @brief Test emoji unigram generation
 */
TEST(StringUtilsTest, EmojiUnigrams) {
  auto ngrams = GenerateNgrams("ğŸ˜€ğŸ‰ğŸ‘", 1);
  ASSERT_EQ(ngrams.size(), 3);
  EXPECT_EQ(ngrams[0], "ğŸ˜€");
  EXPECT_EQ(ngrams[1], "ğŸ‰");
  EXPECT_EQ(ngrams[2], "ğŸ‘");
}

/**
 * @brief Test emoji bigram generation
 */
TEST(StringUtilsTest, EmojiBigrams) {
  auto ngrams = GenerateNgrams("ğŸ˜€ğŸ‰ğŸ‘", 2);
  ASSERT_EQ(ngrams.size(), 2);
  EXPECT_EQ(ngrams[0], "ğŸ˜€ğŸ‰");
  EXPECT_EQ(ngrams[1], "ğŸ‰ğŸ‘");
}

/**
 * @brief Test emoji with mixed text ngrams
 */
TEST(StringUtilsTest, EmojiMixedNgrams) {
  // "HelloğŸ˜€" - unigrams
  auto ngrams = GenerateNgrams("HelloğŸ˜€", 1);
  ASSERT_EQ(ngrams.size(), 6);
  EXPECT_EQ(ngrams[0], "H");
  EXPECT_EQ(ngrams[1], "e");
  EXPECT_EQ(ngrams[2], "l");
  EXPECT_EQ(ngrams[3], "l");
  EXPECT_EQ(ngrams[4], "o");
  EXPECT_EQ(ngrams[5], "ğŸ˜€");

  // "æ—¥æœ¬ğŸ˜€èª" - bigrams
  ngrams = GenerateNgrams("æ—¥æœ¬ğŸ˜€èª", 2);
  ASSERT_EQ(ngrams.size(), 3);
  EXPECT_EQ(ngrams[0], "æ—¥æœ¬");
  EXPECT_EQ(ngrams[1], "æœ¬ğŸ˜€");
  EXPECT_EQ(ngrams[2], "ğŸ˜€èª");
}

/**
 * @brief Test complex emoji (with ZWJ - Zero Width Joiner)
 */
TEST(StringUtilsTest, ComplexEmoji) {
  // Family emoji: ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ (U+1F468 U+200D U+1F469 U+200D U+1F467 U+200D U+1F466)
  // This is actually multiple codepoints joined with ZWJ (U+200D)
  std::string family = "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦";
  auto codepoints = Utf8ToCodepoints(family);

  // Should have 7 codepoints: man, ZWJ, woman, ZWJ, girl, ZWJ, boy
  EXPECT_GE(codepoints.size(), 4);  // At least the base emojis

  // Round trip should preserve the emoji
  std::string result = CodepointsToUtf8(codepoints);
  EXPECT_EQ(result, family);
}

/**
 * @brief Test emoji with skin tone modifiers
 */
TEST(StringUtilsTest, EmojiSkinTone) {
  // Thumbs up with medium skin tone: ğŸ‘ğŸ½ (U+1F44D U+1F3FD)
  std::string thumbs = "ğŸ‘ğŸ½";
  auto codepoints = Utf8ToCodepoints(thumbs);

  // Should have 2 codepoints: thumbs up + skin tone modifier
  ASSERT_EQ(codepoints.size(), 2);
  EXPECT_EQ(codepoints[0], 0x1F44D);  // ğŸ‘
  EXPECT_EQ(codepoints[1], 0x1F3FD);  // ğŸ½ (medium skin tone)

  // Round trip
  std::string result = CodepointsToUtf8(codepoints);
  EXPECT_EQ(result, thumbs);
}

#ifdef USE_ICU
/**
 * @brief Test emoji normalization
 */
TEST(StringUtilsTest, EmojiNormalization) {
  // Emojis should pass through normalization unchanged
  std::string normalized = NormalizeText("HelloğŸ˜€ä¸–ç•ŒğŸ‰", true, "keep", true);
  EXPECT_EQ(normalized, "helloğŸ˜€ä¸–ç•ŒğŸ‰");  // Only ASCII lowercased

  // Emoji with Japanese text
  normalized = NormalizeText("ãƒ©ã‚¤ãƒ–ğŸ˜€æ¥½ã—ã„ğŸ‰", true, "keep", false);
  EXPECT_EQ(normalized, "ãƒ©ã‚¤ãƒ–ğŸ˜€æ¥½ã—ã„ğŸ‰");  // Emojis preserved
}
#endif  // USE_ICU
