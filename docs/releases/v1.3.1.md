# MygramDB v1.3.1 Release Notes

**Release Date:** 2025-11-24
**Type:** Patch Release (Critical Bug Fixes)
**Previous Version:** v1.3.0

---

## Overview

Version 1.3.1 is a critical patch release that addresses multiple data corruption vulnerabilities and replication race conditions discovered immediately after v1.3.0. This release fixes critical bugs that could cause data loss during concurrent operations, replication corruption during SYNC operations, and system crashes due to logging configuration errors.

**‚ö†Ô∏è CRITICAL: All v1.3.0 users should upgrade immediately to prevent data corruption and replication issues.**

---

## üêõ Critical Bug Fixes

### 1. Replication Corruption After SYNC Operations

**Severity:** Critical - Data Loss Risk

**Problem:** After `SYNC` command completes and GTID is updated, replication is not automatically restarted, causing new binlog events to be ignored and leading to data corruption.

**Impact:**
- Data loss between SYNC completion and manual replication restart
- Silent data corruption (no error messages)
- Binlog events skipped during gap period
- Inconsistent state between MySQL and MygramDB

**Root Cause:** SYNC operation updates GTID but does not restart replication automatically. Subsequent binlog events are silently ignored until user manually issues `REPLICATION START`.

**Fix:**
- Automatically restart replication with updated GTID after SYNC completes
- Add automatic replication restart to `SyncOperationManager::PerformSync()` (lines 275-291)
- Block manual `REPLICATION START` during SYNC to prevent race conditions
- Comprehensive replication state management

**Files Changed:**
- `src/server/sync_operation_manager.cpp`: Auto-restart replication after SYNC
- `src/server/handlers/replication_handler.cpp`: Block REPLICATION START during SYNC
- `tests/server/replication_handler_test.cpp`: Add test for GTID validation and blocking

**Testing:** 198 lines of new tests for replication restart and GTID validation scenarios.

---

### 2. Replication Start Before Initial SYNC - GTID Validation

**Severity:** Critical - Data Corruption Risk

**Problem:** Users can issue `REPLICATION START` before initial `SYNC`, causing replication to start with uninitialized GTID (empty string), leading to data corruption.

**Impact:**
- Data corruption from replaying all binlog events from beginning
- Duplicate data in index
- Inconsistent state between MySQL and MygramDB
- No validation or error message

**Root Cause:** No GTID validation in `REPLICATION START` command handler. Empty GTID is passed to BinlogReader, which accepts it as valid position.

**Fix:**
- Add GTID validation in `ReplicationHandler::HandleReplicationStart()` (lines 45-53)
- Block `REPLICATION START` when GTID is uninitialized (empty string)
- Return clear error message: "ERROR: Cannot start replication: GTID not initialized. Run SYNC first"
- Prevent data corruption from invalid replication state

**Files Changed:**
- `src/server/handlers/replication_handler.cpp`: Add GTID validation check
- `tests/server/replication_handler_test.cpp`: Add comprehensive GTID validation tests

**Testing:** New test cases verify GTID validation blocks replication start when GTID is empty.

---

### 3. Logging Configuration Crash on File Logger Path Change

**Severity:** Critical - System Crash

**Problem:** Setting file logger path via `SET logging.file_path` or `SET logging.file_enabled` causes system crash due to incorrect initialization order in ConfigurationManager.

**Impact:**
- Immediate system crash on configuration change
- No error message or recovery
- Service downtime
- Requires manual restart

**Root Cause:** ConfigurationManager initializes file logger before console logger. When file logger configuration changes, it attempts to log to console before console logger is initialized.

**Fix:**
- Reorder initialization sequence in `ConfigurationManager::InitializeLogging()` (lines 108-120)
- Initialize console logger before file logger
- Ensure logging infrastructure is ready before any configuration changes
- Add initialization order validation

**Files Changed:**
- `src/app/configuration_manager.cpp`: Reorder logger initialization
- `src/config/config.cpp`: Fix initialization sequence (lines 85-97)
- `tests/app/configuration_manager_test.cpp`: Add 343 lines of tests for SET/SHOW VARIABLES

**Testing:** Comprehensive tests for configuration manager initialization and runtime variable changes.

---

### 4. Missing Mutual Exclusion Checks - Data Corruption Prevention

**Severity:** Critical - Data Corruption Risk

**Problem:** Multiple concurrent database operations (DUMP, OPTIMIZE, SYNC, REPLICATION) can run simultaneously, causing data corruption due to race conditions and conflicting operations.

**Impact:**
- Data corruption from concurrent modifications during snapshots
- Index corruption from optimization during reload
- Replication corruption from binlog apply during data reload
- Silent data corruption (no error messages)
- Undefined behavior from race conditions

**Affected Operations:**

#### DUMP SAVE Issues:
- ‚ùå Can run during concurrent `DUMP LOAD` ‚Üí snapshot during reload corrupts data
- ‚ùå Can run during another `DUMP SAVE` ‚Üí concurrent saves corrupt dump file
- ‚ùå Warning only during `SYNC` ‚Üí should be error to enforce consistency
- ‚ùå No GTID validation ‚Üí inconsistent dump snapshots

#### DUMP LOAD Issues:
- ‚ùå Can run during `OPTIMIZE` ‚Üí reload during optimization corrupts index
- ‚ùå Can run during `DUMP SAVE` ‚Üí reload during snapshot corrupts data
- ‚ùå Can run during another `DUMP LOAD` ‚Üí concurrent loads cause undefined behavior

#### OPTIMIZE Issues:
- ‚ùå Can run during `SYNC` ‚Üí optimization during snapshot sync corrupts data
- ‚ùå Can run during `DUMP LOAD` ‚Üí optimization during reload corrupts index
- ‚ùå Can run during another `OPTIMIZE` ‚Üí concurrent optimization corrupts index

#### SET VARIABLES Issues:
- ‚ùå Can change `mysql.host` and `mysql.port` during `SYNC` ‚Üí connection switch during snapshot corrupts data

#### REPLICATION START Issues:
- ‚ùå Can run during `DUMP LOAD` ‚Üí binlog apply during data reload corrupts data

**Fix:** Add comprehensive mutual exclusion checks to all command handlers:

**DUMP SAVE fixes:**
- Block during concurrent `DUMP LOAD` (prevent reload during snapshot)
- Block during another `DUMP SAVE` (prevent concurrent saves)
- Upgrade SYNC warning to error (enforce data consistency requirement)
- Require GTID before save (ensure consistent dump snapshots)

**DUMP LOAD fixes:**
- Block during `OPTIMIZE` (prevent reload during optimization)
- Block during `DUMP SAVE` (prevent reload during snapshot)
- Block during another `DUMP LOAD` (prevent concurrent loads)

**OPTIMIZE fixes:**
- Block during `SYNC` (prevent optimization during snapshot sync)
- Block during `DUMP LOAD` (prevent optimization during data reload)
- Allow during `DUMP SAVE` (both are read operations, safe concurrently)
- Block during another `OPTIMIZE` (prevent concurrent optimization)

**SET VARIABLES fixes:**
- Block `mysql.host` and `mysql.port` changes during `SYNC` (prevent connection switching during snapshot operations)

**REPLICATION START fixes:**
- Block during `DUMP LOAD` (prevent binlog apply during data reload)
- Allow during `DUMP SAVE` (both are read operations, safe concurrently)

**Files Changed:**
- `src/server/handlers/debug_handler.cpp`: OPTIMIZE mutual exclusion checks
- `src/server/handlers/dump_handler.cpp`: DUMP SAVE/LOAD mutual exclusion
- `src/server/handlers/replication_handler.cpp`: REPLICATION START blocking
- `src/server/handlers/variable_handler.cpp`: SET VARIABLES blocking
- `tests/server/debug_handler_test.cpp`: 7 tests for OPTIMIZE blocking (228 lines)
- `tests/server/variable_handler_test.cpp`: Tests for SET blocking (207 lines)
- `tests/server/dump_handler_test.cpp`: 6 mutual exclusion tests
- `tests/server/replication_handler_test.cpp`: 2 DUMP LOAD blocking tests
- `tests/app/configuration_manager_test.cpp`: Fix spdlog cleanup issues

**Testing:** 838 lines of new tests covering all mutual exclusion scenarios.

---

### 5. TTL Expiration Not Implemented in QueryCache

**Severity:** High - Memory Leak and Stale Data

**Problem:** QueryCache accepts TTL configuration but never expires entries. Cache grows unbounded and serves stale data indefinitely.

**Impact:**
- Memory leak from unbounded cache growth
- Stale data served to users
- Cache effectiveness degraded over time
- Configuration option (`cache.ttl_seconds`) has no effect

**Root Cause:** QueryCache stores TTL but `Lookup()` and `LookupWithMetadata()` methods never check expiration timestamps. Entries remain in cache forever regardless of TTL setting.

**Fix:**
- Add TTL expiration checks in `Lookup()` and `LookupWithMetadata()` methods
- Expired entries treated as cache misses (increment `cache_misses_not_found`)
- Add `SetTtl()` and `GetTtl()` methods for runtime TTL configuration
- Update `QueryCache` constructor to accept `ttl_seconds` parameter (default 0)
- `CacheManager` now passes TTL to QueryCache on initialization
- `CacheManager::SetTtl()` applies changes immediately to QueryCache

**Files Changed:**
- `src/cache/query_cache.cpp`: Add TTL expiration logic
- `src/cache/query_cache.h`: Add TTL methods and configuration
- `src/cache/cache_manager.cpp`: Pass TTL to QueryCache
- `src/cache/cache_manager.h`: Add TTL configuration methods
- `tests/cache/query_cache_test.cpp`: 163 lines of comprehensive TTL tests

**Testing:** 5 comprehensive test cases:
- `TTLBasicExpiration`: Verify 2-second TTL expiration
- `TTLDisabled`: Verify TTL=0 disables expiration
- `TTLRuntimeUpdate`: Verify `SetTtl()` applies immediately
- `TTLWithMetadataLookup`: Verify `LookupWithMetadata` respects TTL
- `TTLMultipleEntriesExpiration`: Verify differential aging

---

### 6. Rate Limiter Callback Signature Mismatch

**Severity:** Medium - Feature Not Working

**Problem:** RuntimeVariableManager callback signature mismatch prevents rate limiter from responding to `SET api.rate_limiting.enable` commands.

**Impact:**
- `SET api.rate_limiting.enable` has no effect on rate limiter
- Rate limiter cannot be toggled at runtime
- Configuration inconsistency between RuntimeVariableManager and ServerOrchestrator

**Root Cause:** RuntimeVariableManager callback passes `(capacity, refill_rate)` but ServerOrchestrator expects `(enabled, capacity, refill_rate)`. The `enabled` state was not propagated.

**Fix:**
- Update RuntimeVariableManager callback from `(capacity, refill_rate)` to `(enabled, capacity, refill_rate)`
- `ApplyRateLimitingEnable()` now invokes callback to notify rate limiter
- All callback invocations pass enabled state along with capacity and refill_rate
- ServerOrchestrator suppresses unused `enabled` parameter with explicit comment
- Update all test mocks to match new signature (11 test files)

**Files Changed:**
- `src/config/runtime_variable_manager.cpp`: Update callback signature
- `src/config/runtime_variable_manager.h`: Update callback type
- `src/app/server_orchestrator.cpp`: Update callback parameter handling
- `tests/config/runtime_variable_manager_test.cpp`: Update 7 rate limiter callback tests

**Testing:** All existing tests updated to use new callback signature.

---

### 7. DocID Overflow Logic Simplification

**Severity:** Low - Code Quality and Maintainability

**Problem:** Complex overflow handling logic in `DocumentStore::AddDocument()` with defensive checks that were never tested and difficult to understand.

**Root Cause:** Two-branch logic with complex wraparound handling and defensive checks for theoretical edge cases.

**Fix:**
- Simplify overflow handling in `DocumentStore::AddDocument()`
- Check for exhaustion upfront (`next_doc_id_ == 0`)
- Assign current DocID before increment
- Handle UINT32_MAX wraparound explicitly with clear comment
- Remove complex two-branch logic and defensive checks

**Files Changed:**
- `src/storage/document_store.cpp`: Simplify overflow logic (lines 34+)

**Testing:** Existing tests continue to pass with simplified logic.

---

### 8. BinlogReader Performance Optimization

**Severity:** Medium - Performance Improvement

**Problem:** BinlogEvent objects are large (contains event data, metadata, filter values) and were being copied during queue operations, causing significant performance overhead.

**Impact:**
- High CPU usage from expensive object copying
- Increased memory allocations
- Lower throughput during high replication load

**Fix:**
- Change event queue from `std::queue<BinlogEvent>` to `std::queue<std::unique_ptr<BinlogEvent>>`
- Eliminate expensive copying of large BinlogEvent objects
- Use move semantics in `PushEvent()` and `PopEvent()`
- Update worker thread to dereference `unique_ptr` for event processing

**Files Changed:**
- `src/mysql/binlog_reader.cpp`: Update queue and event handling
- `src/mysql/binlog_reader.h`: Update queue type definition
- `tests/mysql/binlog_reader_core_test.cpp`: Update tests for unique_ptr (54 lines changed)
- `tests/mysql/binlog_reader_test.cpp`: Update tests for unique_ptr (45 lines changed)

**Performance Impact:** Significant reduction in CPU usage and memory allocations during binlog event processing.

---

### 9. Replication Race Conditions During MySQL Reconnection and DUMP Operations

**Severity:** Critical - Race Condition and Data Corruption

**Problem:** Manual `REPLICATION START` can interfere with automatic replication management during MySQL reconnection and DUMP operations, causing race conditions and data corruption.

**Impact:**
- Race conditions when user issues `REPLICATION START` during MySQL reconnection
- Data corruption when replication starts during `DUMP LOAD`
- Undefined behavior from concurrent replication state changes
- Silent failures and inconsistent state

**Root Cause:** No blocking mechanism to prevent manual `REPLICATION START` during automatic replication management operations (MySQL reconnection, DUMP LOAD).

**Fix:** Add state flags to block manual REPLICATION START during critical operations:

**State Flag Infrastructure:**
- Add `mysql_reconnecting` flag to block manual REPLICATION START during MySQL reconnection
- Add `replication_paused_for_dump` flag to block manual REPLICATION START during DUMP operations
- Prevent race conditions when automatic replication management is in progress
- `MysqlReconnectionHandler` now sets/clears `mysql_reconnecting` flag on all code paths
- All flag updates occur before/after critical sections for proper synchronization

**TcpServer owns both atomic flags:**
- `std::atomic<bool> mysql_reconnecting_{false}`
- `std::atomic<bool> replication_paused_for_dump_{false}`
- Provides access methods for handlers

**ServerLifecycleManager integration:**
- Passes flag references to HandlerContext
- Flags used by `ReplicationHandler` to block manual REPLICATION START
- Flags used by `MysqlReconnectionHandler` and `DumpHandler` for state management

**Files Changed:**
- `src/server/tcp_server.h`: Add state flag members and access methods
- `src/server/tcp_server.cpp`: Initialize flags
- `src/server/server_types.h`: Add flag references to HandlerContext
- `src/server/server_lifecycle_manager.cpp`: Pass flag references to handlers
- `src/server/server_lifecycle_manager.h`: Update handler signatures
- `src/server/handlers/replication_handler.cpp`: Check flags before allowing REPLICATION START
- `src/app/mysql_reconnection_handler.cpp`: Set/clear `mysql_reconnecting` flag
- `src/app/mysql_reconnection_handler.h`: Update signatures
- `src/server/handlers/dump_handler.cpp`: Set/clear `replication_paused_for_dump` flag
- `tests/server/*_test.cpp`: Update all 10 server handler tests with new flag parameters
- `tests/server/server_lifecycle_manager_test.cpp`: Verify flag references are correctly passed

**Testing:** All handler tests updated to initialize and verify state flag behavior.

---

### 10. Code Quality Improvements

**Severity:** Low - Code Quality

**Improvements:**
- Add `NOLINT` suppression with explanation for selectivity magic numbers in `Index::SearchAnd()` (clang-tidy compliance)
- Extract complex boolean expressions to lambdas for clang-tidy compliance:
  - `src/mysql/binlog_event_parser.cpp`: Event type validation lambdas
  - `src/mysql/binlog_reader.cpp`: Connection state validation
  - `src/server/handlers/dump_handler.cpp`: Operation state checks
- Refactor compound conditionals to switch statements:
  - `src/loader/initial_loader.cpp`: Filter type handling
- Add RuntimeVariableManager parameter validation
- Make `StructuredLog` format changes thread-safe using atomic operations (`structured_log.h` lines 164-169)

**Files Changed:**
- `src/index/index.cpp`: Add NOLINT with explanation
- `src/mysql/binlog_event_parser.cpp`: Lambda refactoring
- `src/mysql/binlog_reader.cpp`: Lambda refactoring
- `src/server/handlers/dump_handler.cpp`: Lambda refactoring
- `src/loader/initial_loader.cpp`: Switch statement refactoring
- `src/config/runtime_variable_manager.cpp`: Parameter validation
- `src/utils/structured_log.h`: Thread-safe format changes

---

## üìö Documentation

### New Documentation

**docs/en/replication_management.md** (227 lines)
- Comprehensive guide to replication management
- Automatic replication management for DUMP/SYNC/MySQL reconnection
- Manual REPLICATION START blocking conditions
- State flag definitions and implementation locations
- Testing strategy and validation procedures

**docs/ja/replication_management.md** (227 lines)
- Japanese translation of replication management guide
- Complete bilingual documentation coverage

---

## üß™ Testing

### Test Coverage Summary

- **Total new test cases**: 52+ across multiple test files
- **Total new test code**: 1,228+ lines
- **All critical bugs covered**: Comprehensive test coverage for all fixes

### New Test Files and Additions

1. **tests/server/debug_handler_test.cpp** (232 lines)
   - 7 tests for OPTIMIZE mutual exclusion
   - Verify blocking during SYNC, DUMP LOAD, concurrent OPTIMIZE

2. **tests/server/variable_handler_test.cpp** (211 lines)
   - Tests for SET VARIABLES blocking during SYNC
   - Verify mysql.host/port changes blocked during snapshot operations

3. **tests/server/replication_handler_test.cpp** (285 lines)
   - GTID validation tests
   - DUMP LOAD blocking tests
   - Replication state management tests

4. **tests/server/dump_handler_test.cpp** (+233 lines)
   - 6 new mutual exclusion tests
   - DUMP SAVE/LOAD concurrent operation tests

5. **tests/cache/query_cache_test.cpp** (+163 lines)
   - 5 comprehensive TTL expiration tests
   - Runtime TTL configuration tests

6. **tests/app/configuration_manager_test.cpp** (364 lines)
   - 343 lines of new tests for SET/SHOW VARIABLES
   - Configuration initialization order tests
   - Test fixture for spdlog cleanup

7. **tests/config/runtime_variable_manager_test.cpp** (+13 lines)
   - 7 updated rate limiter callback tests with new signature

8. **tests/mysql/binlog_reader_core_test.cpp** (+54 lines)
   - Updated for unique_ptr event handling

9. **tests/mysql/binlog_reader_test.cpp** (+45 lines)
   - Updated for unique_ptr event handling

10. **tests/server/server_lifecycle_manager_test.cpp** (+6 lines)
    - Verify state flag references passed correctly

11. **tests/loader/CMakeLists.txt**
    - Increase discovery timeout to 5 seconds for CI stability

---

## üìä Statistics

### Code Changes

- **Files Changed**: 53
- **Insertions**: +2,883 lines
- **Deletions**: -325 lines
- **Net Change**: +2,558 lines

### Module Breakdown

| Module | Files | Description |
|--------|-------|-------------|
| Server | 11 | Mutual exclusion, state flags, handler updates |
| Tests | 11 | Comprehensive test coverage for all fixes |
| Cache | 4 | TTL expiration implementation |
| MySQL | 6 | BinlogReader performance, event handling |
| Config | 3 | RuntimeVariableManager callback fixes |
| App | 3 | Configuration manager, MySQL reconnection |
| Loader | 2 | Initial loader refactoring |
| Utils | 1 | StructuredLog thread safety |
| Docs | 2 | Replication management guide (EN/JA) |
| CMake | 2 | Test configuration updates |

---

## üîÑ Migration Guide

### From v1.3.0 to v1.3.1

**‚ö†Ô∏è URGENT: All v1.3.0 users should upgrade immediately.**

**No configuration changes required.** This is a transparent bug fix release.

### Critical Issues Fixed

If you are running v1.3.0, you may have experienced:
- Data loss after SYNC operations (replication not restarted)
- Data corruption from concurrent DUMP/OPTIMIZE/SYNC operations
- System crashes when changing logging configuration
- Stale data served from cache (TTL not enforced)
- Inability to toggle rate limiting at runtime

### Upgrade Steps

**Docker users:**

```bash
# Pull new image
docker pull ghcr.io/libraz/mygram-db:v1.3.1

# Update docker-compose.yml
services:
  mygramdb:
    image: ghcr.io/libraz/mygram-db:v1.3.1
```

**RPM users:**

```bash
# Download and install
sudo rpm -Uvh mygramdb-1.3.1-1.el9.x86_64.rpm

# Restart service
sudo systemctl restart mygramdb
```

**Source build:**

```bash
git checkout v1.3.1
cmake -B build -DCMAKE_BUILD_TYPE=Release
cmake --build build --parallel
sudo systemctl restart mygramdb
```

### Verification After Upgrade

**1. Verify replication is running:**

```bash
echo "REPLICATION STATUS" | nc localhost 3307
# Should show: running or appropriate state
```

**2. Verify GTID is initialized:**

```bash
echo "SHOW VARIABLES LIKE 'gtid%'" | nc localhost 3307
# Should show valid GTID, not empty string
```

**3. Check logs for errors:**

```bash
tail -f /var/log/mygramdb/mygramdb.log
# Should not show replication errors or corruption warnings
```

**4. Verify cache TTL (if enabled):**

```bash
echo "SHOW VARIABLES LIKE 'cache.ttl%'" | nc localhost 3307
# Should show configured TTL value
```

### Rollback Procedure

If issues arise, rollback to v1.3.0 is possible but NOT RECOMMENDED due to critical bugs:

```bash
# Docker
docker pull ghcr.io/libraz/mygram-db:v1.3.0

# RPM
sudo rpm -Uvh --oldpackage mygramdb-1.3.0-1.el9.x86_64.rpm
```

**‚ö†Ô∏è Warning:** Rolling back to v1.3.0 exposes you to all critical bugs fixed in v1.3.1.

---

## üöÄ Upgrade Recommendation

### Priority: CRITICAL - Upgrade Immediately

**All v1.3.0 deployments should upgrade to v1.3.1 immediately.**

**Affected Scenarios:**

1. **Data Corruption Risk - Critical**
   - Any deployment using SYNC operations
   - Any deployment with concurrent operations (DUMP/OPTIMIZE/SYNC)
   - Risk: Silent data loss and corruption

2. **System Crash Risk - Critical**
   - Any deployment changing logging configuration at runtime
   - Risk: Immediate system crash requiring manual restart

3. **Memory Leak Risk - High**
   - Any deployment with query cache enabled and TTL configured
   - Risk: Unbounded memory growth and stale data

4. **Race Condition Risk - Critical**
   - Any deployment using MySQL failover or DUMP operations
   - Risk: Replication corruption and data loss

5. **Feature Not Working - Medium**
   - Any deployment attempting to toggle rate limiting at runtime
   - Impact: Configuration changes have no effect

---

## üìà Performance Impact

### Positive Impact

- **BinlogReader Performance**: Significant reduction in CPU usage and memory allocations from eliminating BinlogEvent copying
- **QueryCache Memory**: TTL expiration prevents unbounded memory growth
- **Logging Overhead**: Thread-safe StructuredLog format changes reduce contention

### No Negative Impact

All fixes are transparent improvements with no performance degradation.

---

## üîó Links

- **Full Changelog**: [v1.3.0...v1.3.1](https://github.com/libraz/mygram-db/compare/v1.3.0...v1.3.1)
- **Docker Image**: [ghcr.io/libraz/mygram-db](https://github.com/libraz/mygram-db/pkgs/container/mygram-db)
- **Configuration Reference**: [docs/en/configuration.md](../en/configuration.md)
- **Replication Management Guide**: [docs/en/replication_management.md](../en/replication_management.md)

---

## üìß Support

Questions or Issues?

- GitHub Issues: <https://github.com/libraz/mygram-db/issues>
- Documentation: `docs/` directory
- Discussions: <https://github.com/libraz/mygram-db/discussions>

---

**Recommended Version:** v1.3.1

**Release Tag:** `git tag -a v1.3.1 -m "MygramDB v1.3.1: Critical bug fixes for data corruption and race conditions"`
